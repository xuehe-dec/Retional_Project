{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0e38409-2271-40ef-bae3-ff6a5288b9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Lambda, Dense, Flatten, Dropout\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam, Adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cb7bcd7-d76c-47e0-a841-2ce7016634c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "train_path = r'/Users/hexue/pyproject/retina_classification/Retinal Fundus Images/train'\n",
    "test_path = r'/Users/hexue/pyproject/retina_classification/Retinal Fundus Images/test'\n",
    "val_path = r'/Users/hexue/pyproject/retina_classification/Retinal Fundus Images/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0d9b79b-31a3-46d6-8ff2-db64f2b52da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model= tf.keras.applications.EfficientNetB4(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False, pooling='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e421b524-ae7e-4e2a-80b6-2a126cf0e01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=base_model.output\n",
    "x=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n",
    "x = Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n",
    "                bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n",
    "x=Dropout(rate=.45, seed=123)(x)        \n",
    "output=Dense(11, activation='softmax')(x)\n",
    "model=Model(inputs=base_model.input, outputs=output)\n",
    "#for windows\n",
    "#model.compile(Adamax(learning_rate=.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#for mac\n",
    "model.compile(tf.keras.optimizers.legacy.Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4906845d-2ecc-4cc4-a2ce-fb9fd086f47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info( test_gen, preds, print_code, save_dir, subject ):\n",
    "    class_dict=test_gen.class_indices\n",
    "    labels= test_gen.labels\n",
    "    file_names= test_gen.filenames \n",
    "    error_list=[]\n",
    "    true_class=[]\n",
    "    pred_class=[]\n",
    "    prob_list=[]\n",
    "    new_dict={}\n",
    "    error_indices=[]\n",
    "    y_pred=[]\n",
    "    for key,value in class_dict.items():\n",
    "        new_dict[value]=key             # dictionary {integer of class number: string of class name}\n",
    "    # store new_dict as a text fine in the save_dir\n",
    "    classes=list(new_dict.values())     # list of string of class names     \n",
    "    errors=0      \n",
    "    for i, p in enumerate(preds):\n",
    "        pred_index=np.argmax(p)         \n",
    "        true_index=labels[i]  # labels are integer values\n",
    "        if pred_index != true_index: # a misclassification has occurred\n",
    "            error_list.append(file_names[i])\n",
    "            true_class.append(new_dict[true_index])\n",
    "            pred_class.append(new_dict[pred_index])\n",
    "            prob_list.append(p[pred_index])\n",
    "            error_indices.append(true_index)            \n",
    "            errors=errors + 1\n",
    "        y_pred.append(pred_index)    \n",
    "    if print_code !=0:\n",
    "        if errors>0:\n",
    "            if print_code>errors:\n",
    "                r=errors\n",
    "            else:\n",
    "                r=print_code           \n",
    "            msg='{0:^28s}{1:^28s}{2:^28s}{3:^16s}'.format('Filename', 'Predicted Class' , 'True Class', 'Probability')\n",
    "            print_in_color(msg, (0,255,0),(55,65,80))\n",
    "            for i in range(r):                \n",
    "                split1=os.path.split(error_list[i])                \n",
    "                split2=os.path.split(split1[0])                \n",
    "                fname=split2[1] + '/' + split1[1]\n",
    "                msg='{0:^28s}{1:^28s}{2:^28s}{3:4s}{4:^6.4f}'.format(fname, pred_class[i],true_class[i], ' ', prob_list[i])\n",
    "                print_in_color(msg, (255,255,255), (55,65,60))\n",
    "                print(error_list[i]  , pred_class[i], true_class[i], prob_list[i])               \n",
    "        else:\n",
    "            msg='With accuracy of 100 % there are no errors to print'\n",
    "            print_in_color(msg, (0,255,0),(55,65,80))\n",
    "    if errors>0:\n",
    "        plot_bar=[]\n",
    "        plot_class=[]\n",
    "        for  key, value in new_dict.items():        \n",
    "            count=error_indices.count(key) \n",
    "            if count!=0:\n",
    "                plot_bar.append(count) # list containg how many times a class c had an error\n",
    "                plot_class.append(value)   # stores the class \n",
    "        fig=plt.figure()\n",
    "        fig.set_figheight(len(plot_class)/3)\n",
    "        fig.set_figwidth(10)\n",
    "        plt.style.use('fivethirtyeight')\n",
    "        for i in range(0, len(plot_class)):\n",
    "            c=plot_class[i]\n",
    "            x=plot_bar[i]\n",
    "            plt.barh(c, x, )\n",
    "            plt.title( ' Errors by Class on Test Set')\n",
    "    y_true= np.array(labels)        \n",
    "    y_pred=np.array(y_pred)\n",
    "    print(y_true)\n",
    "    print(y_pred)\n",
    "    if len(classes)<= 30:\n",
    "        # create a confusion matrix \n",
    "        cm = confusion_matrix(y_true, y_pred )        \n",
    "        length=len(classes)\n",
    "        if length<8:\n",
    "            fig_width=8\n",
    "            fig_height=8\n",
    "        else:\n",
    "            fig_width= int(length * .5)\n",
    "            fig_height= int(length * .5)\n",
    "        plt.figure(figsize=(fig_width, fig_height))\n",
    "        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n",
    "        plt.xticks(np.arange(length)+.5, classes, rotation= 90)\n",
    "        plt.yticks(np.arange(length)+.5, classes, rotation=0)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "    clr = classification_report(y_true, y_pred, target_names=classes)\n",
    "    print(\"Classification Report:\\n----------------------\\n\", clr)\n",
    "def print_in_color(txt_msg,fore_tupple,back_tupple,):\n",
    "    #prints the text_msg in the foreground color specified by fore_tupple with the background specified by back_tupple \n",
    "    #text_msg is the text, fore_tupple is foregroud color tupple (r,g,b), back_tupple is background tupple (r,g,b)\n",
    "    rf,gf,bf=fore_tupple\n",
    "    rb,gb,bb=back_tupple\n",
    "    msg='{0}' + txt_msg\n",
    "    mat='\\33[38;2;' + str(rf) +';' + str(gf) + ';' + str(bf) + ';48;2;' + str(rb) + ';' +str(gb) + ';' + str(bb) +'m' \n",
    "    print(msg .format(mat), flush=True)\n",
    "    print('\\33[0m', flush=True) # returns default print color to back to black\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9764cb2c-2ac5-4e60-85b4-fc7934205324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20077 images belonging to 11 classes.\n",
      "Found 1236 images belonging to 11 classes.\n",
      "Found 433 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "shear_range = 0.2,\n",
    "zoom_range = 0.2,\n",
    "horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "training_set = train_datagen.flow_from_directory(directory=train_path,\n",
    "target_size = (224,224),\n",
    "batch_size = 32,\n",
    "class_mode = 'categorical')\n",
    "test_set = test_datagen.flow_from_directory(directory=test_path,\n",
    "target_size = (224,224),\n",
    "batch_size = 32,\n",
    "class_mode = 'categorical')\n",
    "val_set = test_datagen.flow_from_directory(directory=val_path,\n",
    "target_size = (224,224),\n",
    "batch_size = 32,\n",
    "class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54a3034c-d979-462b-8637-b87ce4365f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 17:01:56.793664: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-12-13 17:01:56.835896: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "\u001b[38;2;0;255;0;48;2;55;65;80m          Filename                Predicted Class                True Class           Probability   \n",
      "\u001b[0m\n",
      "\u001b[38;2;255;255;255;48;2;55;65;60m1.Dry AMD/Dry AMD102_left_0_9315.jpeg 8.Hypertensive Retinopathy          1.Dry AMD              0.4163\n",
      "\u001b[0m\n",
      "1.Dry AMD/Dry AMD102_left_0_9315.jpeg 8.Hypertensive Retinopathy 1.Dry AMD 0.41627464\n",
      "\u001b[38;2;255;255;255;48;2;55;65;60m1.Dry AMD/Dry AMD102_left_0_9943.jpeg        5.Severe DR                  1.Dry AMD              0.3857\n",
      "\u001b[0m\n",
      "1.Dry AMD/Dry AMD102_left_0_9943.jpeg 5.Severe DR 1.Dry AMD 0.38565284\n",
      "\u001b[38;2;255;255;255;48;2;55;65;60m1.Dry AMD/Dry AMD102_right_0_116.jpeg        5.Severe DR                  1.Dry AMD              0.6508\n",
      "\u001b[0m\n",
      "1.Dry AMD/Dry AMD102_right_0_116.jpeg 5.Severe DR 1.Dry AMD 0.6507956\n",
      "\u001b[38;2;255;255;255;48;2;55;65;60m1.Dry AMD/Dry AMD102_right_0_3112.jpeg        5.Severe DR                  1.Dry AMD              0.5810\n",
      "\u001b[0m\n",
      "1.Dry AMD/Dry AMD102_right_0_3112.jpeg 5.Severe DR 1.Dry AMD 0.58101606\n",
      "\u001b[38;2;255;255;255;48;2;55;65;60m1.Dry AMD/Dry AMD102_right_0_4731.jpeg        5.Severe DR                  1.Dry AMD              0.6203\n",
      "\u001b[0m\n",
      "1.Dry AMD/Dry AMD102_right_0_4731.jpeg 5.Severe DR 1.Dry AMD 0.6203252\n",
      "\u001b[38;2;255;255;255;48;2;55;65;60m1.Dry AMD/Dry AMD102_right_0_6903.jpeg 8.Hypertensive Retinopathy          1.Dry AMD              0.6583\n",
      "\u001b[0m\n",
      "1.Dry AMD/Dry AMD102_right_0_6903.jpeg 8.Hypertensive Retinopathy 1.Dry AMD 0.6582831\n",
      "\u001b[38;2;255;255;255;48;2;55;65;60m1.Dry AMD/Dry AMD152_right_0_4137.jpeg        5.Severe DR                  1.Dry AMD              0.4615\n",
      "\u001b[0m\n",
      "1.Dry AMD/Dry AMD152_right_0_4137.jpeg 5.Severe DR 1.Dry AMD 0.4615465\n",
      "\u001b[38;2;255;255;255;48;2;55;65;60m1.Dry AMD/Dry AMD152_right_0_5413.jpeg        5.Severe DR                  1.Dry AMD              0.6522\n",
      "\u001b[0m\n",
      "1.Dry AMD/Dry AMD152_right_0_5413.jpeg 5.Severe DR 1.Dry AMD 0.65220815\n",
      "\u001b[38;2;255;255;255;48;2;55;65;60m1.Dry AMD/Dry AMD168_left_0_7590.jpeg        5.Severe DR                  1.Dry AMD              0.6521\n",
      "\u001b[0m\n",
      "1.Dry AMD/Dry AMD168_left_0_7590.jpeg 5.Severe DR 1.Dry AMD 0.65211767\n",
      "\u001b[38;2;255;255;255;48;2;55;65;60m1.Dry AMD/Dry AMD168_left_0_9746.jpeg        5.Severe DR                  1.Dry AMD              0.6780\n",
      "\u001b[0m\n",
      "1.Dry AMD/Dry AMD168_left_0_9746.jpeg 5.Severe DR 1.Dry AMD 0.677952\n",
      "[ 0  0  0 ... 10 10 10]\n",
      "[9 6 6 6 6 9 6 6 6 6 6 6 6 9 6 9 6 9 6 6 6 6 6 6 6 9 6 9 6 9 6 6]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1236, 32]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m print_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      9\u001b[0m preds\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(test_set, steps\u001b[38;5;241m=\u001b[39mtest_steps, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \n\u001b[0;32m---> 10\u001b[0m print_info( test_set, preds, print_code, working_dir, subject )\n",
      "Cell \u001b[0;32mIn[10], line 69\u001b[0m, in \u001b[0;36mprint_info\u001b[0;34m(test_gen, preds, print_code, save_dir, subject)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_pred)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(classes)\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# create a confusion matrix \u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_true, y_pred )        \n\u001b[1;32m     70\u001b[0m     length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(classes)\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m length\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m8\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/cvenv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/cvenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:326\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    232\u001b[0m     {\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    243\u001b[0m ):\n\u001b[1;32m    244\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[0;32m~/anaconda3/envs/cvenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[1;32m     85\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/cvenv/lib/python3.11/site-packages/sklearn/utils/validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    407\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    412\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1236, 32]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x33.3333 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "length=len(test_set)\n",
    "subject='eye disease'\n",
    "test_batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=80],reverse=True)[0]  \n",
    "test_steps=int(length/test_batch_size)\n",
    "working_dir = r'./'\n",
    "print_code=10\n",
    "preds=model.predict(test_set, steps=test_steps, verbose=1) \n",
    "print_info( test_set, preds, print_code, working_dir, subject )  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5a73441-d5e5-4d8c-b256-730baceb76b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 17:02:16.408569: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 35s 891ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mpredict(test_set)\n\u001b[0;32m----> 2\u001b[0m lt\u001b[38;5;241m.\u001b[39mplot(m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lt' is not defined"
     ]
    }
   ],
   "source": [
    "model.predict(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908dd65f-cbe5-4689-ab53-f4c76aff3790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 17:04:13.180078: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/628 [..............................] - ETA: 3:41:36 - loss: 11.7404 - accuracy: 0.0469"
     ]
    }
   ],
   "source": [
    "m = model.fit(\n",
    "  training_set,\n",
    "  validation_data=val_set,\n",
    "  epochs=20,\n",
    "  batch_size=128,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set),\n",
    "  shuffle=False,\n",
    "  initial_epoch=0\n",
    ")\n",
    "plt.plot(m.history['loss'], label='Train loss')\n",
    "plt.plot(m.history['val_loss'], label='Validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')\n",
    "\n",
    "# plot the accuracy\n",
    "plt.plot(m.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(m.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('AccVal_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b72c7aa-097c-4d5b-9d99-fa0bc9fd2f04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
